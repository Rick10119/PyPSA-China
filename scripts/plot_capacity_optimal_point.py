#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Plot scatter chart of optimal points showing capacity and net value
X-axis: Aluminum smelting capacity (10,000 tons/year)
Y-axis: Net value (billion CNY)
Different years represented by different colors
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging
import yaml
import argparse
import copy
import glob
import re
from scipy import stats
from scipy.stats import norm
import hashlib
import json

# Set Chinese font
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# Set logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def load_config(config_path):
    """
    Load configuration file
    
    Parameters:
    -----------
    config_path : str or Path
        Configuration file path
        
    Returns:
    --------
    dict
        Configuration content
    """
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        logger.error(f"Error loading configuration file {config_path}: {str(e)}")
        return None

def generate_cache_key(base_version, capacity_ratios, results_dir):
    """
    Generate cache key based on parameters
    
    Parameters:
    -----------
    base_version : str
        Base version number
    capacity_ratios : list
        List of capacity ratios
    results_dir : str
        Results directory
        
    Returns:
    --------
    str
        Cache key
    """
    # Create a string representation of all parameters
    params_str = f"{base_version}_{'-'.join(capacity_ratios)}_{results_dir}"
    # Generate hash
    return hashlib.md5(params_str.encode()).hexdigest()

def save_optimal_points_cache(optimal_points, cache_key, cache_dir='results/optimal_points_analysis'):
    """
    Save optimal points data to CSV cache
    
    Parameters:
    -----------
    optimal_points : list
        List of optimal points data
    cache_key : str
        Cache key
    cache_dir : str
        Cache directory
    """
    try:
        cache_path = Path(cache_dir)
        cache_path.mkdir(parents=True, exist_ok=True)
        
        # Convert to DataFrame
        df = pd.DataFrame(optimal_points)
        
        # Save data
        csv_file = cache_path / f"optimal_points_cache_{cache_key}.csv"
        df.to_csv(csv_file, index=False)
        
        # Save metadata
        metadata = {
            'cache_key': cache_key,
            'timestamp': pd.Timestamp.now().isoformat(),
            'num_points': len(optimal_points),
            'years': sorted(list(set([point['year'] for point in optimal_points]))),
            'markets': sorted(list(set([point['market'] for point in optimal_points]))),
            'flexibilities': sorted(list(set([point['flexibility'] for point in optimal_points])))
        }
        
        metadata_file = cache_path / f"optimal_points_metadata_{cache_key}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Optimal points data cached to: {csv_file}")
        logger.info(f"Metadata cached to: {metadata_file}")
        
    except Exception as e:
        logger.error(f"Error saving cache: {str(e)}")

def load_optimal_points_cache(cache_key, cache_dir='results/optimal_points_analysis'):
    """
    Load optimal points data from CSV cache
    
    Parameters:
    -----------
    cache_key : str
        Cache key
    cache_dir : str
        Cache directory
        
    Returns:
    --------
    list or None
        List of optimal points data if cache exists and is valid, None otherwise
    """
    try:
        cache_path = Path(cache_dir)
        csv_file = cache_path / f"optimal_points_cache_{cache_key}.csv"
        metadata_file = cache_path / f"optimal_points_metadata_{cache_key}.json"
        
        # Check if both files exist
        if not csv_file.exists() or not metadata_file.exists():
            logger.info("Cache files not found")
            return None
        
        # Load metadata
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # Check if cache is recent (within 24 hours)
        cache_time = pd.Timestamp(metadata['timestamp'])
        if pd.Timestamp.now() - cache_time > pd.Timedelta(hours=24):
            logger.info("Cache is outdated (older than 24 hours)")
            return None
        
        # Load data
        df = pd.read_csv(csv_file)
        optimal_points = df.to_dict('records')
        
        # Convert year back to int
        for point in optimal_points:
            point['year'] = int(point['year'])
        
        logger.info(f"Loaded optimal points from cache: {len(optimal_points)} points")
        logger.info(f"Cache contains years: {metadata['years']}")
        logger.info(f"Cache contains markets: {metadata['markets']}")
        logger.info(f"Cache contains flexibilities: {metadata['flexibilities']}")
        
        return optimal_points
        
    except Exception as e:
        logger.error(f"Error loading cache: {str(e)}")
        return None

def save_optimal_points_to_csv(optimal_points, plot_type, output_dir='results/optimal_points_analysis'):
    """
    Save optimal points data to CSV file for easy migration
    
    Parameters:
    -----------
    optimal_points : list
        List of optimal points data
    plot_type : str
        Type of plot (for filename)
    output_dir : str
        Output directory
    """
    try:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Convert to DataFrame
        df = pd.DataFrame(optimal_points)
        
        # Add additional calculated columns
        demand_by_year = {
            2030: 2902.417177819193,
            2040: 1508.1703393209764,
            2050: 1166.6836345743664,
        }
        
        # Calculate excess ratio for each point
        excess_ratios = []
        for point in optimal_points:
            capacity = point['capacity'] * 100  # Convert to 10,000 tons/year
            demand = demand_by_year.get(point['year'], 0)
            excess_ratio = calculate_excess_ratio(capacity, demand)
            excess_ratios.append(excess_ratio)
        
        df['excess_ratio'] = excess_ratios
        df['demand_10k_tons'] = df['year'].map(demand_by_year)
        df['capacity_10k_tons'] = df['capacity'] * 100
        
        # Reorder columns for better readability
        column_order = ['year', 'market', 'flexibility', 'capacity', 'capacity_10k_tons', 
                       'net_value', 'excess_ratio', 'demand_10k_tons']
        df = df[column_order]
        
        # Save to CSV
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        csv_file = output_path / f"{plot_type}_data_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        # Also save a version without timestamp for easy access
        csv_file_latest = output_path / f"{plot_type}_data_latest.csv"
        df.to_csv(csv_file_latest, index=False, encoding='utf-8')
        
        logger.info(f"Optimal points data saved to: {csv_file}")
        logger.info(f"Latest data also saved to: {csv_file_latest}")
        
        # Print summary statistics
        logger.info(f"Data summary:")
        logger.info(f"  Total points: {len(df)}")
        logger.info(f"  Years: {sorted(df['year'].unique())}")
        logger.info(f"  Markets: {sorted(df['market'].unique())}")
        logger.info(f"  Flexibilities: {sorted(df['flexibility'].unique())}")
        logger.info(f"  Capacity range: {df['capacity'].min():.1f} - {df['capacity'].max():.1f} (10k tons/year)")
        logger.info(f"  Net value range: {df['net_value'].min():.2f} - {df['net_value'].max():.2f} (Billion CNY)")
        
    except Exception as e:
        logger.error(f"Error saving CSV: {str(e)}")

def find_available_years(results_dir, base_version):
    """
    Find available year data
    
    Parameters:
    -----------
    results_dir : str
        Results directory
    base_version : str
        Base version number
        
    Returns:
    --------
    list
        List of available years
    """
    available_years = []
    results_path = Path(results_dir)
    
    # Find all possible year directories
    for year in [2030, 2040, 2050]:
        # Find version directories containing this year
        year_pattern = f"version-{base_version}-*{year}*"
        version_dirs = list(results_path.glob(year_pattern))
        
        for version_dir in version_dirs:
            # Check if data exists for this year
            summary_dir = version_dir / 'summary' / 'postnetworks' / 'positive'
            if summary_dir.exists():
                year_pattern = f"postnetwork-ll-current+Neighbor-linear2050-{year}"
                year_dir = summary_dir / year_pattern
                if year_dir.exists() and (year_dir / 'costs.csv').exists():
                    available_years.append(year)
                    break
    
    # If no years found, default to 2050
    if not available_years:
        available_years = [2050]
        logger.warning("No year data found, defaulting to 2050")
    
    return sorted(list(set(available_years)))

def load_costs_data(version_name, year, results_dir='results'):
    """
    Load cost data for specified version
    
    Parameters:
    -----------
    version_name : str
        Version name, e.g. '0814.4H.2-MMM-2050-100p'
    year : int
        Year
    results_dir : str
        Results directory
        
    Returns:
    --------
    pd.DataFrame or None
        Cost data
    """
    try:
        # Build file path
        file_path = Path(f"{results_dir}/version-{version_name}/summary/postnetworks/positive/postnetwork-ll-current+Neighbor-linear2050-{year}/costs.csv")
        
        if not file_path.exists():
            logger.warning(f"File does not exist: {file_path}")
            return None
        
        # Read CSV file
        df = pd.read_csv(file_path, header=None)
        
        # Handle multi-level index structure
        if len(df.columns) >= 4:
            # Set multi-level index: first two columns as index, third column as technology name
            df.set_index([0, 1, 2], inplace=True)
            # Rename last column as numeric column name
            df.columns = [df.columns[0]]
            # Convert numeric column to numeric type
            df[df.columns[0]] = pd.to_numeric(df[df.columns[0]], errors='coerce')
        else:
            # If insufficient columns, use default multi-level index
            df = pd.read_csv(file_path, index_col=[0, 1])
            numeric_col = df.columns[0]
            df[numeric_col] = pd.to_numeric(df[numeric_col], errors='coerce')
        
        return df
        
    except Exception as e:
        logger.error(f"Error loading data: {str(e)}")
        return None

def calculate_cost_categories(costs_data):
    """
    Calculate cost categories
    
    Parameters:
    -----------
    costs_data : pd.DataFrame
        Cost data
        
    Returns:
    --------
    dict
        Cost data organized by category
    """
    if costs_data is None or costs_data.empty:
        return {}
    
    # Define cost type and resource combination category mapping
    cost_category_mapping = {
        # variable cost-non-renewable - Non-renewable energy variable costs
        ('marginal', 'coal'): 'variable cost-non-renewable',
        ('marginal', 'coal power plant'): 'variable cost-non-renewable',
        ('marginal', 'coal cc'): 'variable cost-non-renewable',
        ('marginal', 'gas'): 'variable cost-non-renewable',
        ('marginal', 'nuclear'): 'variable cost-non-renewable',
        ('marginal', 'CHP coal'): 'variable cost-non-renewable',
        ('marginal', 'CHP gas'): 'variable cost-non-renewable',
        ('marginal', 'OCGT gas'): 'variable cost-non-renewable',
        ('marginal', 'coal boiler'): 'variable cost-non-renewable',
        ('marginal', 'gas boiler'): 'variable cost-non-renewable',
        
        # capital-non-renewable - Non-renewable energy capital costs
        ('capital', 'coal'): 'capital-non-renewable',
        ('capital', 'coal power plant'): 'capital-non-renewable',
        ('capital', 'coal cc'): 'capital-non-renewable',
        ('capital', 'gas'): 'capital-non-renewable',
        ('capital', 'nuclear'): 'capital-non-renewable',
        ('capital', 'CHP coal'): 'capital-non-renewable',
        ('capital', 'CHP gas'): 'capital-non-renewable',
        ('capital', 'OCGT gas'): 'capital-non-renewable',
        ('capital', 'coal boiler'): 'capital-non-renewable',
        ('capital', 'gas boiler'): 'capital-non-renewable',
        
        # capital-demand side - Demand-side capital costs
        ('capital', 'heat pump'): 'heating-electrification',
        ('capital', 'resistive heater'): 'heating-electrification',
        
        # capital-renewable - Renewable energy capital costs
        ('capital', 'hydro_inflow'): 'capital-renewable',
        ('capital', 'hydroelectricity'): 'capital-renewable',
        ('capital', 'offwind'): 'capital-renewable',
        ('capital', 'onwind'): 'capital-renewable',
        ('capital', 'solar'): 'capital-renewable',
        ('capital', 'solar thermal'): 'capital-renewable',
        ('capital', 'biomass'): 'capital-renewable',
        ('capital', 'biogas'): 'capital-renewable',
        
        # transmission lines - Transmission lines
        ('capital', 'AC'): 'transmission lines',
        ('capital', 'stations'): 'transmission lines',
        
        # batteries - Battery storage
        ('capital', 'battery'): 'batteries',
        ('capital', 'battery discharger'): 'batteries',
        ('marginal', 'battery'): 'batteries',
        ('marginal', 'battery discharger'): 'batteries',
        
        # long-duration storages - Long-duration storage
        ('capital', 'PHS'): 'long-duration storages',
        ('capital', 'water tanks'): 'long-duration storages',
        ('capital', 'H2'): 'long-duration storages',
        ('capital', 'H2 CHP'): 'long-duration storages',
        ('marginal', 'PHS'): 'long-duration storages',
        ('marginal', 'water tanks'): 'long-duration storages',
        ('marginal', 'H2'): 'long-duration storages',
        ('marginal', 'H2 CHP'): 'long-duration storages',
        
        # Other categories
        ('capital', 'CO2 capture'): 'capital-non-renewable',
        ('marginal', 'CO2 capture'): 'variable cost-non-renewable',
        ('capital', 'Sabatier'): 'capital-non-renewable',
        ('marginal', 'Sabatier'): 'variable cost-non-renewable',
        ('capital', 'CO2'): 'capital-non-renewable',
        ('marginal', 'CO2'): 'variable cost-non-renewable',
        ('capital', 'DAC'): 'capital-non-renewable',
        ('marginal', 'DAC'): 'variable cost-non-renewable',
    }
    
    # Organize data by cost category
    category_costs = {}
    
    for idx in costs_data.index:
        if len(idx) >= 3:
            component_type, cost_type, carrier = idx[0], idx[1], idx[2]
            
            # Use category mapping
            category_key = (cost_type, carrier)
            category_name = cost_category_mapping.get(category_key, f"{cost_type} - {carrier}")
            
            if category_name not in category_costs:
                category_costs[category_name] = 0
            
            value = costs_data.loc[idx].iloc[0]
            if not pd.isna(value):
                category_costs[category_name] += value
    
    return category_costs

def calculate_total_emissions_from_costs(costs_data):
    """
    Calculate total carbon emissions from cost data (estimated through coal and gas marginal costs)
    
    Parameters:
    -----------
    costs_data : pd.DataFrame
        Cost data
        
    Returns:
    --------
    float
        Total carbon emissions (tons CO2)
    """
    if costs_data is None or costs_data.empty:
        return 0
    
    total_emissions = 0
    
    for idx in costs_data.index:
        if len(idx) >= 3:
            component_type, cost_type, carrier = idx[0], idx[1], idx[2]
            if isinstance(carrier, str) and 'coal' in carrier.lower() and cost_type == 'marginal':
                value = costs_data.loc[idx].iloc[0]
                if pd.notna(value):
                    total_emissions += value
            elif isinstance(carrier, str) and 'gas' in carrier.lower() and cost_type == 'marginal':
                value = costs_data.loc[idx].iloc[0]
                if pd.notna(value):
                    total_emissions += value
    
    return total_emissions



def calculate_actual_capacity_ratio(year: int, cap_ratio: float, demand_level: str) -> float:
    """
    Calculate actual capacity ratio
    
    Args:
        year: Year
        cap_ratio: Excess capacity retention ratio (e.g., 0.1 means 10%)
        demand_level: Demand level ('mid')
        
    Returns:
        Actual capacity ratio
    """
    # Total capacity
    total_capacity = 4500
    
    # Set demand by year (using actual data)
    demand_by_year = {
        "2030": 2902.417177819193,
        "2040": 1508.1703393209764,
        "2050": 1166.6836345743664,
    }
    
    demand = demand_by_year.get(str(year), 0)
    
    # Calculate actual capacity ratio: demand/capacity × (1-cap) + cap
    actual_ratio = (demand / total_capacity) * (1 - cap_ratio) + cap_ratio
    
    return actual_ratio

def find_optimal_points(base_version, capacity_ratios, results_dir='results', use_cache=True):
    """
    Find optimal points for each year-market-flexibility combination
    
    Parameters:
    -----------
    base_version : str
        Base version number
    capacity_ratios : list
        List of capacity ratios
    results_dir : str
        Results directory
    use_cache : bool
        Whether to use cache if available
        
    Returns:
    --------
    list
        List containing optimal point information, each element is (year, market, flexibility, capacity, net_value)
    """
    # Generate cache key
    cache_key = generate_cache_key(base_version, capacity_ratios, results_dir)
    
    # Try to load from cache first
    if use_cache:
        cached_data = load_optimal_points_cache(cache_key)
        if cached_data is not None:
            logger.info("Using cached optimal points data")
            return cached_data
        else:
            logger.info("Cache not available or outdated, computing optimal points...")
    
    # Euro to CNY conversion rate
    EUR_TO_CNY = 7.8
    
    # Find available years
    available_years = find_available_years(results_dir, base_version)
    logger.info(f"Found available years: {available_years}")
    
    # Define market opportunities and flexibility levels
    markets = ['L', 'M', 'H']
    flexibilities = ['L', 'M', 'H', 'N']  # low, mid, high, non_constrained
    
    optimal_points = []
    
    for year in available_years:
        for market in markets:
            for flexibility in flexibilities:
                logger.info(f"Analyzing optimal point for {year}-{market}-{flexibility}...")
                
                # Build version names - use different base_version for different scenarios
                # Extract the base part and construct scenario-specific base_version
                base_parts = base_version.split('-')
                if len(base_parts) >= 2:
                    # Use the scenario part (e.g., MMM, HML, etc.) from base_version
                    scenario_part = base_parts[1]  # e.g., "MMM", "HML", etc.
                    scenario_base_version = f"{base_parts[0]}-{scenario_part}"
                else:
                    # Fallback to original base_version
                    scenario_base_version = base_version
                
                version_names = []
                config_versions = {}
                
                for ratio in capacity_ratios:
                    # Version format: scenario_base_version-{flexibility}{demand}{market}-{year}-{ratio}
                    # Demand is fixed as 'M' (mid)
                    version = f"{scenario_base_version}-{flexibility}M{market}-{year}-{ratio}"
                    version_names.append(version)
                    config_versions[ratio] = version
                
                # Baseline versions
                aluminum_baseline_version = f"{scenario_base_version}-{flexibility}M{market}-{year}-5p"
                power_baseline_version = f"{scenario_base_version}-{flexibility}M{market}-{year}-non_flexible"
                
                # Collect data
                costs_data = {}
                baseline_data = {}
                
                # Load baseline data
                aluminum_baseline = load_costs_data(aluminum_baseline_version, year, results_dir)
                if aluminum_baseline is not None:
                    baseline_data['aluminum'] = aluminum_baseline
                
                power_baseline = load_costs_data(power_baseline_version, year, results_dir)
                if power_baseline is not None:
                    baseline_data['power'] = power_baseline
                
                # Load data for each capacity ratio
                for ratio in capacity_ratios:
                    version_name = config_versions[ratio]
                    costs = load_costs_data(version_name, year, results_dir)
                    if costs is not None:
                        costs_data[ratio] = costs
                
                if not costs_data or not baseline_data:
                    logger.warning(f"No data found for {year}-{market}-{flexibility}")
                    continue
                
                # Calculate net values (same method as plot_capacity_multi_year_market_comparison)
                power_cost_changes = []
                aluminum_cost_changes = []
                capacity_values = []
                
                for ratio in capacity_ratios:
                    if ratio in costs_data and 'power' in baseline_data:
                        # Calculate power system cost changes (cost reduction is positive)
                        current_costs = calculate_cost_categories(costs_data[ratio])
                        baseline_costs = calculate_cost_categories(baseline_data['power'])
                        
                        # Calculate total cost change (excluding aluminum related)
                        power_cost_change = 0
                        for category, value in current_costs.items():
                            if 'aluminum' not in category.lower():
                                baseline_value = baseline_costs.get(category, 0)
                                power_cost_change += (value - baseline_value)
                        
                        # Cost reduction is positive direction, so take negative value
                        power_cost_changes.append(-power_cost_change * EUR_TO_CNY)
                    else:
                        power_cost_changes.append(0)
                    
                    if ratio in costs_data and 'aluminum' in baseline_data:
                        # Calculate aluminum cost changes (cost reduction is positive)
                        current_costs = calculate_cost_categories(costs_data[ratio])
                        baseline_costs = calculate_cost_categories(baseline_data['aluminum'])
                        
                        # Calculate aluminum related cost changes
                        aluminum_cost_change = 0
                        for category, value in current_costs.items():
                            if 'aluminum' in category.lower():
                                baseline_value = baseline_costs.get(category, 0)
                                aluminum_cost_change += (value - baseline_value)
                        
                        # Cost reduction is positive direction, so take negative value
                        aluminum_cost_changes.append(-aluminum_cost_change * EUR_TO_CNY)
                    else:
                        aluminum_cost_changes.append(0)
                    
                    # Read capacity ratio values and calculate actual capacity
                    scenario_suffix = f"{flexibility}M{market}"
                    config_file = f"configs/config_{scenario_suffix}_{year}_{ratio}.yaml"
                    config = load_config(config_file)
                    capacity_ratio = config.get('aluminum_capacity_ratio', 1.0)
                    if 'aluminum' in config and 'capacity_ratio' in config['aluminum']:
                        capacity_ratio = config['aluminum']['capacity_ratio']
                    
                    # Calculate actual capacity using the same method as generate_capacity_test_configs
                    # Convert cap_ratio from percentage to decimal (e.g., "10p" -> 0.1)
                    cap_ratio_decimal = float(ratio.replace('p', '')) / 100.0
                    actual_capacity_ratio = calculate_actual_capacity_ratio(year, cap_ratio_decimal, 'mid')
                    # Calculate actual capacity in 10,000 tons/year (4500 * actual_capacity_ratio)
                    actual_capacity = 45 * actual_capacity_ratio
                    capacity_values.append(actual_capacity)
                
                # Calculate net cost savings (same as plot_capacity_multi_year_market_comparison)
                net_cost_savings = [power_cost_changes[i] + aluminum_cost_changes[i] for i in range(len(capacity_values))]
                
                # Find the point with maximum net savings
                if net_cost_savings:
                    max_saving_index = np.argmax(net_cost_savings)
                    optimal_capacity = capacity_values[max_saving_index]
                    optimal_net_value = net_cost_savings[max_saving_index]
                    
                    optimal_points.append({
                        'year': year,
                        'market': market,
                        'flexibility': flexibility,
                        'capacity': optimal_capacity,
                        'net_value': optimal_net_value / 1e9  # Convert to billion CNY
                    })
                    
                    logger.info(f"{year}-{market}-{flexibility} optimal point: capacity={optimal_capacity:.1f} 10,000 tons/year, net_value={optimal_net_value/1e9:.2f}B CNY")
    
    # Save to cache
    if optimal_points:
        save_optimal_points_cache(optimal_points, cache_key)
    
    return optimal_points

def calculate_excess_ratio(capacity, demand):
    """
    Calculate excess ratio: 1 - (demand/capacity)
    
    Parameters:
    -----------
    capacity : float
        Actual capacity (10,000 tons/year)
    demand : float
        Demand (10,000 tons/year)
        
    Returns:
    --------
    float
        Excess ratio
    """
    excess_ratio = 1 - (demand / capacity) if capacity > 0 else 0
    return excess_ratio

def plot_optimal_points_distribution(use_cache=True, save_csv=True):
    """
    Plot optimal points distribution
    Top: Point distribution and density function of optimal excess ratio
    Bottom: Distribution and probability density function of optimal net value
    """
    from scipy import stats
    from scipy.stats import norm
    
    # Load base version from main config file
    main_config = load_config('config.yaml')
    if main_config is None:
        logger.error("Cannot load main config file config.yaml")
        return
    
    base_version = main_config.get('version', '0815.1H.1')
    logger.info(f"Loaded base version from main config: {base_version}")
    
    # Define capacity ratios
    capacity_ratios = ['5p', '10p', '20p', '30p', '40p', '50p', '60p', '70p', '80p', '90p', '100p']
    
    # Find all optimal points
    optimal_points = find_optimal_points(base_version, capacity_ratios, 'results', use_cache)
    
    if not optimal_points:
        logger.error("No optimal point data found")
        return
    
    # Save data to CSV if requested
    if save_csv:
        save_optimal_points_to_csv(optimal_points, 'optimal_points_distribution')
    
    # Group data by year
    years = sorted(list(set([point['year'] for point in optimal_points])))
    
    # Demand data (10,000 tons/year)
    demand_by_year = {
        2030: 2902.417177819193,
        2040: 1508.1703393209764,
        2050: 1166.6836345743664,
    }
    
    # Calculate excess ratio and net value for each year
    year_data = {}
    for year in years:
        year_points = [point for point in optimal_points if point['year'] == year]
        excess_ratios = []
        net_values = []
        
        for point in year_points:
            # Calculate excess ratio: 1 - (demand/retention_ratio)
            capacity = point['capacity'] * 100  # Convert to 10,000 tons/year
            demand = demand_by_year.get(year, 0)
            excess_ratio = calculate_excess_ratio(capacity, demand)
            excess_ratios.append(excess_ratio)
            net_values.append(point['net_value'])
        
        year_data[year] = {
            'excess_ratios': excess_ratios,
            'net_values': net_values
        }
    
    # Create subplots
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # Color settings
    colors = plt.cm.viridis(np.linspace(0, 1, len(years)))
    year_colors = dict(zip(years, colors))
    
    # Top plot: Optimal excess ratio distribution
    ax1.set_title('Optimal Excess Ratio Distribution', fontsize=16, fontweight='bold', pad=20)
    
    for year in years:
        excess_ratios = year_data[year]['excess_ratios']
        if len(excess_ratios) > 1:  # Need at least 2 points to fit distribution
            # Plot scatter points
            x_positions = np.random.normal(year, 0.1, len(excess_ratios))  # Add small random offset to avoid overlap
            ax1.scatter(x_positions, excess_ratios, 
                       c=year_colors[year], alpha=0.7, s=100, 
                       label=f'{year} (n={len(excess_ratios)})')
            
            # Fit Gaussian distribution
            mu, sigma = norm.fit(excess_ratios)
            
            # Plot probability density function
            x_range = np.linspace(min(excess_ratios) - 2*sigma, max(excess_ratios) + 2*sigma, 100)
            pdf = norm.pdf(x_range, mu, sigma)
            
            # Scale PDF to appropriate range and offset to corresponding year
            pdf_scaled = pdf * 1.0 + year  # Scale and offset (increased from 0.3 to 1.0)
            ax1.plot(pdf_scaled, x_range, color=year_colors[year], linewidth=3, alpha=0.9)
            
            # Add mean and standard deviation information
            ax1.text(year, max(excess_ratios) + 0.1, f'Mean={mu:.3f}', 
                    ha='center', va='bottom', fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor=year_colors[year], alpha=0.3))
    
    ax1.set_xlabel('Year', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Excess Ratio', fontsize=14, fontweight='bold')
    ax1.set_xticks(years)
    ax1.grid(True, alpha=0.3)
    # ax1.legend(loc='upper right', fontsize=12)  # Removed legend
    
    # Bottom plot: Optimal net value distribution
    ax2.set_title('Optimal Net Value Distribution', fontsize=16, fontweight='bold', pad=20)
    
    for year in years:
        net_values = year_data[year]['net_values']
        if len(net_values) > 1:  # Need at least 2 points to fit distribution
            # Plot scatter points
            x_positions = np.random.normal(year, 0.1, len(net_values))  # Add small random offset to avoid overlap
            ax2.scatter(x_positions, net_values, 
                       c=year_colors[year], alpha=0.7, s=100, 
                       label=f'{year} (n={len(net_values)})')
            
            # Fit Gaussian distribution
            mu, sigma = norm.fit(net_values)
            
            # Plot probability density function
            x_range = np.linspace(min(net_values) - 2*sigma, max(net_values) + 2*sigma, 100)
            pdf = norm.pdf(x_range, mu, sigma)
            
            # Scale PDF to appropriate range and offset to corresponding year
            pdf_scaled = pdf * 1.0 + year  # Scale and offset (increased from 0.3 to 1.0)
            ax2.plot(pdf_scaled, x_range, color=year_colors[year], linewidth=3, alpha=0.9)
            
            # Add mean and standard deviation information
            ax2.text(year, max(net_values) + 0.5, f'Mean={mu:.2f}', 
                    ha='center', va='bottom', fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor=year_colors[year], alpha=0.3))
    
    ax2.set_xlabel('Year', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Net Value (Billion CNY)', fontsize=14, fontweight='bold')
    ax2.set_xticks(years)
    ax2.grid(True, alpha=0.3)
    # ax2.legend(loc='upper right', fontsize=12)  # Removed legend
    
    plt.tight_layout()
    
    # Save plot
    output_dir = Path('results/optimal_points_analysis')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    plot_file = output_dir / "optimal_points_distribution.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    logger.info(f"Optimal points distribution plot saved to: {plot_file}")
    
    # Show plot
    # plt.show()

def plot_optimal_points_boxplot(use_cache=True, save_csv=True):
    """
    Plot box plot of optimal points showing capacity and net value distribution by year
    """
    # Load base version from main config file
    main_config = load_config('config.yaml')
    if main_config is None:
        logger.error("Cannot load main config file config.yaml")
        return
    
    base_version = main_config.get('version', '0815.1H.1')
    logger.info(f"Loaded base version from main config: {base_version}")
    
    # Define capacity ratios
    capacity_ratios = ['5p', '10p', '20p', '30p', '40p', '50p', '60p', '70p', '80p', '90p', '100p']
    
    # Find all optimal points
    optimal_points = find_optimal_points(base_version, capacity_ratios, 'results', use_cache)
    
    if not optimal_points:
        logger.error("No optimal point data found")
        return
    
    # Save data to CSV if requested
    if save_csv:
        save_optimal_points_to_csv(optimal_points, 'optimal_points_boxplot')
    
    # Create box plot
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
    
    # Group data by year
    years = sorted(list(set([point['year'] for point in optimal_points])))
    colors = plt.cm.viridis(np.linspace(0, 1, len(years)))
    year_colors = dict(zip(years, colors))
    
    # Prepare data for box plots
    capacity_data = []
    net_value_data = []
    year_labels = []
    
    for year in years:
        year_points = [point for point in optimal_points if point['year'] == year]
        capacities = [point['capacity'] for point in year_points]
        net_values = [point['net_value'] for point in year_points]
        
        capacity_data.append(capacities)
        net_value_data.append(net_values)
        year_labels.append(f'{year}\n(n={len(capacities)})')
    
    # Left plot: Capacity box plot
    bp1 = ax1.boxplot(capacity_data, labels=year_labels, patch_artist=True, 
                      boxprops=dict(alpha=0.7), medianprops=dict(color='black', linewidth=2))
    
    # Color the boxes
    for patch, year in zip(bp1['boxes'], years):
        patch.set_facecolor(year_colors[year])
    
    ax1.set_title('Optimal Capacity Distribution by Year', fontsize=16, fontweight='bold', pad=20)
    ax1.set_xlabel('Year', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Aluminum Smelting Capacity (10,000 tons/year)', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='both', which='major', labelsize=12)
    
    # Format y-axis to show integers only
    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))
    
    # Add horizontal lines for annual demand by year
    demand_by_year = {
        2030: 29.0241717,
        2040: 15.0817033,
        2050: 11.6668363,
    }
    
    # Colors for demand lines
    demand_colors = {2030: 'red', 2040: 'orange', 2050: 'purple'}
    
    for i, year in enumerate(years, 1):
        if year in demand_by_year:
            demand = demand_by_year[year]
            ax1.axhline(y=demand, xmin=(i-1)/len(years), xmax=i/len(years), 
                       color=demand_colors[year], linestyle='--', linewidth=3, alpha=0.8)
    
    # Right plot: Net value box plot
    bp2 = ax2.boxplot(net_value_data, labels=year_labels, patch_artist=True, 
                      boxprops=dict(alpha=0.7), medianprops=dict(color='black', linewidth=2))
    
    # Color the boxes
    for patch, year in zip(bp2['boxes'], years):
        patch.set_facecolor(year_colors[year])
    
    ax2.set_title('Optimal Net Value Distribution by Year', fontsize=16, fontweight='bold', pad=20)
    ax2.set_xlabel('Year', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Net System Value (Billion CNY)', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis='both', which='major', labelsize=12)
    
    # Format y-axis to show integers only
    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))
    
    # Add legend for years
    legend_elements = []
    for year in years:
        legend_elements.append(plt.Rectangle((0,0),1,1, facecolor=year_colors[year], alpha=0.7, label=f'{year}'))
    
    # Add demand lines to legend
    for year, demand in demand_by_year.items():
        if year in years:
            legend_elements.append(plt.Line2D([0], [0], color=demand_colors[year], linestyle='--', linewidth=3, 
                                            label=f'{year} Demand: {demand:.0f} 10k tons/year'))
    
    # Add legend
    ax1.legend(handles=legend_elements, loc='upper right', fontsize=12)
    
    plt.tight_layout()
    
    # Save plot
    output_dir = Path('results/optimal_points_analysis')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    plot_file = output_dir / "optimal_points_boxplot.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    logger.info(f"Optimal points box plot saved to: {plot_file}")
    
    # Show plot
    # plt.show()

def plot_optimal_points_scatter(use_cache=True, save_csv=True):
    """
    Plot scatter chart of optimal points showing capacity and net value
    """
    # Load base version from main config file
    main_config = load_config('config.yaml')
    if main_config is None:
        logger.error("Cannot load main config file config.yaml")
        return
    
    base_version = main_config.get('version', '0815.1H.1')
    logger.info(f"Loaded base version from main config: {base_version}")
    
    # Define capacity ratios
    capacity_ratios = ['5p', '10p', '20p', '30p', '40p', '50p', '60p', '70p', '80p', '90p', '100p']
    
    # Find all optimal points
    optimal_points = find_optimal_points(base_version, capacity_ratios, 'results', use_cache)
    
    if not optimal_points:
        logger.error("No optimal point data found")
        return
    
    # Save data to CSV if requested
    if save_csv:
        save_optimal_points_to_csv(optimal_points, 'optimal_points_scatter')
    
    # Create scatter plot
    fig, ax = plt.subplots(figsize=(10, 10))
    
    # Group data by year
    years = sorted(list(set([point['year'] for point in optimal_points])))
    colors = plt.cm.viridis(np.linspace(0, 1, len(years)))
    year_colors = dict(zip(years, colors))
    
    # Create different markers for market opportunities
    markets = ['L', 'M', 'H']
    market_markers = {'L': 'o', 'M': 's', 'H': '^'}
    
    # Create different colors for flexibility levels
    flexibilities = ['L', 'M', 'H', 'N']
    flexibility_colors = {'L': 'blue', 'M': 'green', 'H': 'orange', 'N': 'red'}
    
    # Plot scatter points
    for point in optimal_points:
        year = point['year']
        market = point['market']
        flexibility = point['flexibility']
        capacity = point['capacity']
        net_value = point['net_value']
        
        # Use year color for main color, flexibility for edge color
        ax.scatter(capacity, net_value, 
                  c=year_colors[year], 
                  marker=market_markers[market],
                  s=200, alpha=0.7, 
                  edgecolors=flexibility_colors[flexibility], 
                  linewidth=2)
    
    # Add labels
    ax.set_xlabel('Aluminum Smelting Capacity (10,000 tons/year)', fontsize=15, fontweight='bold')
    ax.set_ylabel('Net System Value (Billion CNY)', fontsize=15, fontweight='bold')
    # ax.set_title('Optimal Points Analysis: Capacity vs Net Value', fontsize=16, fontweight='bold')
    
    # Set tick parameters for larger font size and integer formatting
    ax.tick_params(axis='both', which='major', labelsize=14)
    ax.tick_params(axis='both', which='minor', labelsize=12)
    
    # Format x-axis to show integers only
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))
    
    # Format y-axis to show integers only
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))
    
    # Add grid
    ax.grid(True, alpha=0.3)
    
    # Add vertical lines for annual demand by year
    demand_by_year = {
        2030: 29.0241717,
        2040: 15.0817033,
        2050: 11.6668363,
    }
    
    # Colors for demand lines
    demand_colors = {2030: 'red', 2040: 'orange', 2050: 'purple'}
    
    for year, demand in demand_by_year.items():
        if year in years:  # Only plot demand lines for years that have data
            ax.axvline(x=demand, color=demand_colors[year], linestyle='--', linewidth=2, alpha=0.8, 
                       label=f'{year} Demand: {demand:.0f} 10k tons/year')
    
    # Create legend
    legend_elements = []
    
    # Year legend
    for year in years:
        legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', 
                                        markerfacecolor=year_colors[year], 
                                        markersize=15, label=f'{year}'))
    
    # Market legend
    for market in markets:
        market_desc = {'L': 'Low Market', 'M': 'Mid Market', 'H': 'High Market'}
        legend_elements.append(plt.Line2D([0], [0], marker=market_markers[market], 
                                        color='w', markerfacecolor='gray', 
                                        markersize=15, label=market_desc[market]))
    
    # Flexibility legend
    for flexibility in flexibilities:
        flex_desc = {'L': 'Low Flexibility', 'M': 'Mid Flexibility', 'H': 'High Flexibility', 'N': 'Non-constrained'}
        legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', 
                                        markerfacecolor='w', markeredgecolor=flexibility_colors[flexibility],
                                        markersize=15, markeredgewidth=2, label=flex_desc[flexibility]))
    
    # Add demand lines to legend (only for years that have data)
    for year, demand in demand_by_year.items():
        if year in years:
            legend_elements.append(plt.Line2D([0], [0], color=demand_colors[year], linestyle='--', linewidth=2, 
                                            label=f'{year} Demand: {demand:.0f} 10k tons/year'))
    
    # Add legend
    ax.legend(handles=legend_elements, loc='upper right', fontsize=15, ncol=2)
    
    # Add labels for each point
    for point in optimal_points:
        year = point['year']
        market = point['market']
        flexibility = point['flexibility']
        capacity = point['capacity']
        net_value = point['net_value']
        
        ax.annotate(f'{year}-{flexibility}-{market}', 
                   xy=(capacity, net_value),
                   xytext=(5, 5), textcoords='offset points',
                   fontsize=12, alpha=0.8)
    
    plt.tight_layout()
    
    # Save plot
    output_dir = Path('results/optimal_points_analysis')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    plot_file = output_dir / "optimal_points_scatter.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    logger.info(f"Optimal points scatter plot saved to: {plot_file}")
    
    # Show plot
    # plt.show()

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='Plot optimal points distribution showing excess ratio and net value distribution')
    parser.add_argument('--results-dir', default='results', help='Results directory path (default: results)')
    parser.add_argument('--output', default='results/optimal_points_analysis', help='Output directory')
    parser.add_argument('--plot-type', choices=['distribution', 'scatter', 'boxplot'], default='distribution', 
                       help='Plot type: distribution (default), scatter, or boxplot')
    parser.add_argument('--no-cache', action='store_true', 
                       help='Disable cache and force recomputation of optimal points')
    parser.add_argument('--no-csv', action='store_true', 
                       help='Disable CSV output (only generate plots)')
    
    args = parser.parse_args()
    
    # Determine cache usage
    use_cache = not args.no_cache
    save_csv = not args.no_csv
    
    logger.info(f"Starting analysis of optimal points capacity and net value")
    logger.info(f"Results directory: {args.results_dir}")
    logger.info(f"Output directory: {args.output}")
    logger.info(f"Plot type: {args.plot_type}")
    logger.info(f"Use cache: {use_cache}")
    logger.info(f"Save CSV: {save_csv}")
    
    if args.plot_type == 'distribution':
        # Plot optimal points distribution
        plot_optimal_points_distribution(use_cache, save_csv)
    elif args.plot_type == 'scatter':
        # Plot optimal points scatter
        plot_optimal_points_scatter(use_cache, save_csv)
    elif args.plot_type == 'boxplot':
        # Plot optimal points box plot
        plot_optimal_points_boxplot(use_cache, save_csv)
    
    logger.info("Analysis completed!")

if __name__ == "__main__":
    main()
